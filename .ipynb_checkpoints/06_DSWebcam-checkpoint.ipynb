{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI Header.png\" alt=\"Header\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0  Live Stream (Optional)\n",
    "### USB WEBCAM CONNECTED TO JETSON NANO REQUIRED\n",
    "\n",
    "In the examples presented so far, the input stream has been a file, played as a stream.  In this notebook, you'll use a live stream via a webcam. Attach a USB webcam to your Jetson Nano using an available USB port.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/06_example.png\" alt=\"webcam input\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 **[Build a Pipeline with Webcam Input](#06_overview)**<br>\n",
    "&nbsp; &nbsp; &nbsp; 6.1.1 [Practice Application `deepstream-test1-webcam_in`](#06_base)<br>\n",
    "&nbsp; &nbsp; &nbsp; 6.1.2 [Exercise: Build and Run the Base Application](#06_ex_base)<br>\n",
    "6.2 **[Change the Network to YOLO](#06_yolo)**<br>\n",
    "&nbsp; &nbsp; &nbsp; 6.2.1 [Exercise: Run YOLO with a Webcam](#06_ex_yolo)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_overview'></a>\n",
    "# 6.1 Build a Pipeline with Webcam Input\n",
    "The `deepstream-test1-webcam_in` application is a modification of the `deepstream-test1-rstp_out` application you explored in the first notebook. Compare the pipeline elements defined in the C code in [filesrc deepstream_test_app.c](../deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-rtsp_out/deepstream_test1_app.c) with the elements in [the webcam deepstream_test1_app.c](../deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in/deepstream_test1_app.c):\n",
    "\n",
    "**filesrc version**\n",
    "```c\n",
    "...\n",
    "\n",
    "  GstElement *pipeline = NULL, *source = NULL, *h264parser = NULL,\n",
    "      *decoder = NULL, *streammux = NULL, *sink = NULL, *pgie = NULL, *nvvidconv = NULL,\n",
    "      *nvosd = NULL, *encoder = NULL, *rtppay = NULL, *transform = NULL, *cap_filter = NULL;\n",
    "\n",
    "...\n",
    "   /* Source element for reading from the file */\n",
    "  source = gst_element_factory_make (\"filesrc\", \"file-source\");\n",
    "\n",
    "  /* Since the data format in the input file is elementary h264 stream,\n",
    "   * we need a h264parser */\n",
    "  h264parser = gst_element_factory_make (\"h264parse\", \"h264-parser\");\n",
    "\n",
    "  /* Use nvdec_h264 for hardware accelerated decode on GPU */\n",
    "  decoder = gst_element_factory_make (\"nvv4l2decoder\", \"nvv4l2-decoder\");\n",
    "\n",
    "  /* Create nvstreammux instance to form batches from one or more sources. */\n",
    "  streammux = gst_element_factory_make (\"nvstreammux\", \"stream-muxer\");\n",
    "\n",
    "...\n",
    "```\n",
    "**webcam version**\n",
    "```c\n",
    "...\n",
    "    \n",
    "  GstElement *pipeline = NULL, *source = NULL, *nvvidconv_src = NULL, *vidconv_src=NULL, \n",
    "      *filter_src=NULL, *streammux = NULL, *sink = NULL, *pgie = NULL, *nvvidconv = NULL,\n",
    "      *nvosd = NULL, *encoder = NULL, *rtppay = NULL, *transform = NULL, *cap_filter = NULL;\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "  source = gst_element_factory_make (\"v4l2src\", \"camera-source\");\n",
    "  g_object_set (G_OBJECT (source), \"device\", \"/dev/video0\", NULL);\n",
    "  vidconv_src = gst_element_factory_make (\"videoconvert\", \"vidconv_src\");\n",
    "  nvvidconv_src = gst_element_factory_make (\"nvvideoconvert\", \"nvvidconv_src\");\n",
    "  filter_src = gst_element_factory_make (\"capsfilter\", \"filter_src\");\n",
    "  g_object_set (G_OBJECT (nvvidconv_src), \"nvbuf-memory-type\", 0, NULL);\n",
    "  caps_filter_src =\n",
    "        gst_caps_from_string (\"video/x-raw(memory:NVMM), format=NV12, width=1280, height=720, framerate=30/1\");\n",
    "  g_object_set (G_OBJECT (filter_src), \"caps\", caps_filter_src, NULL);\n",
    "  gst_caps_unref (caps_filter_src);\n",
    "\n",
    "  /* Create nvstreammux instance to form batches from one or more sources. */\n",
    "  streammux = gst_element_factory_make (\"nvstreammux\", \"stream-muxer\");\n",
    "```    \n",
    "\n",
    "The remaining elements of the pipeline are the same.\n",
    "\n",
    "In summary, the pipeline for this app consists of the following plugins (ordered):\n",
    "\n",
    "- `GstV4l2Src` - can be used to capture video from v4l2 devices, like webcams and tv cards\n",
    "- `GstVideoConvert` - Convert video frames between a great variety of video formats\n",
    "- `Gst-nvvideoconvert` - performs video color format conversion (I420 to RGBA)\n",
    "- `GstCapsFilter` - enforces limitations on data (no data modification)\n",
    "- `GstH264Parse` - parses the incoming H264 stream\n",
    "- `Gst-nvv4l2decoder` - hardware accelerated decoder; decodes video streams using NVDEC\n",
    "- `Gst-nvstreammux` - batch video streams before sending for AI inference\n",
    "- `Gst-nvinfer` - runs inference using TensorRT\n",
    "- `Gst-nvvideoconvert` - performs video color format conversion (I420 to RGBA)\n",
    "- `Gst-nvdsosd` - draw bounding boxes, text and region of interest (ROI) polygons\n",
    "- `Gst-nvvideoconvert` - performs video color format conversion (RGBA to I420)\n",
    "- `GstCapsFilter` - enforces limitations on data (no data modification)\n",
    "- `Gst-nvv4l2h264enc` - encodes RAW data in I420 format to H264\n",
    "- `GstRtpH264Pay` - converts H264 encoded Payload to RTP packets (RFC 3984)\n",
    "- `GstUDPSink` - sends UDP packets to the network. When paired with RTP payloader (`Gst-rtph264pay`) it can implement RTP streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_base'></a>\n",
    "# 6.1.1 Practice Application `deepstream-test1-webcam_in`\n",
    "This app uses the Resnet10 primary detector provided with the DeepStream SDK.  You'll need to move the webcam over objects that the network can detect, i.e. Vehicle, Person, Bicycle, or Roadsign.  One way to accomplish this is to use a computer screen with these objects visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_ex_base'></a>\n",
    "# 6.1.2 Exercise: Build and Run the Base Application\n",
    "Plug in your webcam and execute the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in/\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the DeepStream app\n",
    "Open the VLC media player on your laptop:\n",
    "- Click \"Media\" and open the  \"Open Network Stream\" dialog.\n",
    "- Set the URL to `rtsp://192.168.55.1:8554/ds-test`.\n",
    "- Start execution of the cell below.\n",
    "- Click \"Play\" on your VLC media player right after you start executing the cell.  \n",
    "\n",
    "The stream will start shortly from the Jetson Nano and display in the media player.  You may experience some lag, or may need to press the play button again on the player.  \n",
    "\n",
    "To stop the stream, click `Kernel -> Interrupt Kernel` from the JupyterLab menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in/\n",
    "!./deepstream-test1-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_yolo'></a>\n",
    "# 6.2 Change the Network to YOLO\n",
    "If you set up the YOLO network in the optional [Using Different Networks]() notebook, you will be able to identify many more objects with your webcam (up to 80!).  The `deepstream-test1-webcam_in-yolo` is very similar to the `deepstream-test1-webcam_in` app, but configured for YOLO.  To see the actual difference in lines, execute the following `diff` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/\n",
    "!diff deepstream-test1-webcam_in/deepstream_test1_app.c deepstream-test1-webcam_in-yolo/deepstream_test1_app.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='06_ex_yolo'></a>\n",
    "# 6.2.1 Run YOLO with a Webcam\n",
    "There will be a delay while the `.engine` file is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in-yolo/\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test1-webcam_in-yolo/\n",
    "!./deepstream-test1-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You've completed all the notebooks.  Be sure to work through the assessment questions in the online portion of the DLI course to get your certificate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI Header.png\" alt=\"Header\" width=\"400\"></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

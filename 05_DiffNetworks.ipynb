{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI Header.png\" alt=\"Header\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Using Different Neural Networks (Optional)\n",
    "### INTERNET CONNECTION TO JETSON NANO REQUIRED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples presented so far, the object detector was a ResNet10 network trained to detect four different objects (Vehicle, Bicycle, Person, Roadsign). In many cases, you may wish to use a different network for other tasks. DeepStream natively supports other networks including YOLO, SSD, and Faster-RCNN. For experienced developers, additional networks can be integrated with DeepStream through TensorRT.  \n",
    "\n",
    "To use these networks, there is some setup that requires internet access.  The easiest way to accomplish this is via the Ethernet port on the Jetson Nano. In this notebook, you'll learn how to incorporate a YOLO network into a DeepStream app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/05_example.png\" alt=\"YOLO network pipeline\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 **[YOLO](#05_yolo)**<br>\n",
    "&nbsp; &nbsp; &nbsp; 5.1.1 [Set Up YOLO with DeepStream SDK](#05_yolos_setup)<br>\n",
    "&nbsp; &nbsp; &nbsp; 5.1.2 [Exercise: Build and Run a YOLO Application](#05_ex_yolo)<br>\n",
    "&nbsp; &nbsp; &nbsp; 5.1.3 [Exercise: Annotate Your Own Video with YOLO](#05_ex_your_video)<br>\n",
    "5.2 **[Faster-RCNN](#05_faster_rcnn)**<br>\n",
    "5.3 **[SSD](#05_ssd)**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"05_yolo\"></a>\n",
    "# 5.1 YOLO\n",
    "The YOLO, or \"You Only Look Once\", network employs a single convolutional network that simultaneously predicts multiple bounding boxes and class probabilities for those boxes.  DeepStream SDK includes support for YOLO in the `/home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/objectDetector_Yolo` directory. Navigate there now using the JupyterLab file browser. Click the `labels.txt` file to view the ordered list of 80 objects that can be detected by this network!\n",
    "\n",
    "Before using it the first time, you'll need to run the setup scripts to download weight and configuration files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"05_setup_yolo\"></a>\n",
    "## 5.1.1 Set Up YOLO with DeepStream SDK\n",
    "Follow these steps to set up YOLO on your Jetson Nano.  Your Jetson Nano must be connected to the Internet.\n",
    "1. Navigate to `/home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/objectDetector_Yolo/nvdsinfer_custom_impl_Yolo` with the JupyterLab file browser.\n",
    "2. Click on `Makefile` to edit.\n",
    "   * Set the CUDA version:  `CUDA_VER=10.0`\n",
    "   * Save and close the file.\n",
    "3. Execute the following cells to make and prebuild YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/objectDetector_Yolo/nvdsinfer_custom_impl_Yolo/\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/objectDetector_Yolo/\n",
    "!./prebuild.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"05_ex_yolo\"></a>\n",
    "## 5.1.2 Exercise: Build and Run a YOLO Application\n",
    "Build and run the following sample application to see YOLO in action.  After running the following cells, deepstream will save the result to `/home/dlinano/out.mp4`.  Download `out.mp4` by right clicking it in JupyterLab file browser and select \"Download\". Then play it on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test3-mp4_out-yolo/\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test3-mp4_out-yolo/\n",
    "!./deepstream-test3-app \\\n",
    "file:///home/dlinano/deepstream_sdk_v4.0.2_jetson/samples/streams/sample_720p.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"05_ex_your_video\"></a>\n",
    "## 5.1.3 Exercise: Annotate Your Own Video with YOLO\n",
    "Since the sample file, `sample_720p.mp4` has mainly cars and people in the scene, you won't see all YOLO has to offer with the 80 objects it can detect.  Try annotating your own video instead of using the provided sample:\n",
    "\n",
    "1. Import your own video file: drag-and-drop it from your machine to JupyterLab file browser.\n",
    "2. Run the following cell with the input path of your imported file. \n",
    "3. The result will be saved to `/home/dlinano/out.mp4` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test3-mp4_out-yolo/\n",
    "!./deepstream-test3-app \\\n",
    "#TODO replace with your own file path\n",
    "file:///your/filepath/here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"05_faster_rcnn\"></a>\n",
    "# 5.2 Faster-RCNN\n",
    "\n",
    "This sample uses TensorRT plugins, performs inference, and implements a fused custom layer for end-to-end inferencing of a Faster R-CNN model. Specifically, this sample demonstrates the implementation of a Faster R-CNN network in TensorRT, performs a quick performance test in TensorRT, implements a fused custom layer, and constructs the basis for further optimization.\n",
    "\n",
    "Navigate to `/home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/objectDetector_FasterRCNN` using the JupyterLab file browser. Click the README for detailed instructions on DeepStream pre-requisites and usage.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"05_ssd\"></a>\n",
    "# 5.3 SSD\n",
    "    \n",
    "The SSD, or \"Single Shot Detector\", network performs the task of object detection and localization in a single forward pass of the network. This network is built using the VGG network as a backbone. Unlike Faster R-CNN, SSD completely eliminates proposal generation and subsequent pixel or feature resampling stages.  It encapsulates all computation in a single network. This makes SSD straightforward to integrate into systems that require a detection component. \n",
    "\n",
    "Navigate to `/home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/objectDetector_SSD` using the JupyterLab file browser. Click the README for detailed instructions on DeepStream pre-requisites and usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You ran a DeepStream app using a different network. <br>\n",
    "Move on to [6.0 Using a Live Stream (Optional)](./06_DSWebcam.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI Header.png\" alt=\"Header\" width=\"400\"></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

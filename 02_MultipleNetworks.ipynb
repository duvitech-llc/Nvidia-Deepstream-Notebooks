{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI Header.png\" alt=\"Header\" width=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Multiple Networks Application\n",
    "Once an object is detected and located in a DeepStream app, it can be further classified by passing the cropped object image through additional network(s) in the pipeline.  Those networks can run image classification inference to provide more information about the objects. In this notebook, you'll work with the `deepstream-test2` reference application to find objects in a video stream, pass those images through classification networks, and finally display detailed information about the objects in the output stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/02_test2_example.png\" alt=\"beginning and end image with pipe\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 **[Build a Pipeline with Multiple Networks in Series](#02_overview)**<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.1.1 [Practice Application `deepstream-test2-rtsp_out-1SGIE`](#02_test2)<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.1.2 [Secondary Network](#02_secondary)<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.1.3 [Exercise: Build and Run the Base Application](#02_ex_base)<br>\n",
    "2.2 **[Add a Plugin to a Pipeline](#02_sgie2)**<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.2.1 [Define](#02_define)<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.2.2 [Instantiate](#02_instantiate)<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.2.3 [Bin and Link](#02_binlink)<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.2.4 [Configure](#02_configure)<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.2.5 [Exercise: Add SGIE2 Plugin to the Pipeline](#02_ex_change)<br>\n",
    "2.3 **[Put It All Together](#02_final)**<br>\n",
    "&nbsp; &nbsp; &nbsp; 2.3.1 [Exercise: Three Secondary Networks](#02_ex_challenge)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_overview'></a>\n",
    "# 2.1 Build a Pipeline with Multiple Networks in Series\n",
    "Multiple instances of the `Gst-nvinfer` plugin (i.e., multiple inference engines), with the addition of one `Gst-nvtracker` plugin, enable multiple neural networks to reside in a single pipeline, resulting in the ability to identify sub-classifications of detected objects. The first instance of the `Gst-nvinfer` plugin serves as the **Primary GPU Inference Engine (PGIE)**. For example, we can start with a PGIE 4-class object detector that detects vehicles, bicycles, persons, and road signs. \n",
    "\n",
    "Subsequent instances of the `Gst-nvinfer` plugin are **Secondary GPU Inference Engines (SGIE)**. During object detection inference, a **region of interest (ROI)** is determined and vertices provided within the metadata. When an object ROI is detected by the PGIE, a link is generated by `Gst-nvtracker` to track the object between frames. The SGIE takes the ROI (i.e., cropped image) as input and provides an output with secondary identifying information (e.g., color, make, type for a vehicle). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_test2'></a>\n",
    "## 2.1.1 Practice Application `deepstream-test2-rtsp_out-1SGIE`\n",
    "The `deepstream_test2` sample application included with the DeepStream SDK has a pipeline that includes a primary detector and three secondary detectors. For this notebook, you will start with a modified version in the `dli_apps` directory that includes the RTSP output and *only one* secondary network.  Execute the next cell to take a look at the application directory. Note that there are now three configuration files: two for the two `Gst-nvinfer` plugins, and one for the `Gst-nvtracker` plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test2-rtsp_out-1SGIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the C code in [deepstream_test2_app.c](../deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test2-rtsp_out-1SGIE/deepstream_test2_app.c).  Here's a look at a snippet showing the plugins linked together using the `gst_bin_add_many()` method, which reveals the architecture of the pipeline to us:\n",
    "\n",
    "```c\n",
    "  /* Set up the pipeline */\n",
    "  /* we add all elements into the pipeline */\n",
    "  /* decoder | pgie1 | nvtracker | sgie1 | sgie2 | sgie3 | etc.. */\n",
    "  gst_bin_add_many (GST_BIN (pipeline),\n",
    "      source, h264parser, decoder, streammux, pgie, nvtracker, sgie1,\n",
    "      nvvidconv, nvosd, transform, cap_filter, encoder, rtppay, sink, NULL);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DeepStream application includes the following plugins in its pipeline:\n",
    "\n",
    "- `GstFileSrc` - reads the video data from file\n",
    "- `GstH264Parse` - parses the incoming H264 stream\n",
    "- `Gst-nvv4l2decoder` - hardware accelerated decoder; decodes video streams using NVDEC\n",
    "- `Gst-nvstreammux` - batch video streams before sending for AI inference\n",
    "- `Gst-nvinfer` - (PGIE) runs inference using TensorRT\n",
    "- `Gst-nvtracker` - tracks object between frames\n",
    "- `Gst-nvinfer` (SGIE1) - runs inference using TensorRT\n",
    "- `Gst-nvvideoconvert` - performs video color format conversion (I420 to RGBA)\n",
    "- `Gst-nvdsosd` - draw bounding boxes, text and region of interest (ROI) polygons\n",
    "- `Gst-nvvideoconvert` - performs video color format conversion (RGBA to I420)\n",
    "- `GstCapsFilter` - enforces limitations on data (no data modification)\n",
    "- `Gst-nvv4l2h264enc` - encodes RAW data in I420 format to H264\n",
    "- `GstRtpH264Pay` - converts H264 encoded Payload to RTP packets (RFC 3984)\n",
    "- `GstUDPSink` - sends UDP packets to the network. When paired with RTP payloader (`Gst-rtph264pay`) it can implement RTP streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_secondary'></a>\n",
    "## 2.1.2 Secondary Networks\n",
    "The pipeline for `deepstream-test2-rtsp_out-1SGIE` is very similar to the `deepstream_test1` object detection sample application you worked with previously. The only real difference is the addition of a tracker and secondary networks (only one secondary network to start with).  The image below gives an idea of how secondary networks fit into the pipeline after the primary detector.\n",
    "\n",
    "<img src=\"images/02_secondary_networks.png\" alt=\"secondary networks\">\n",
    "\n",
    "In `deepstream-test2-rtsp_out-1SGIE`, two plugins are inserted after the `Gst-nvinfer` object detector (PGIE): `Gst-nvtracker`, and one classification network using an additional `Gst-nvinfer` plugin (SGIE1). In a similar way, additional networks can be added to the pipeline by adding more `Gst-nvinfer` plugins to the pipeline (e.g. SGIE2, SGIE3).  You'll try this in a later exercise.  For now, let's build the example with a single secondary network that determines the color of vehicles found by the object detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_ex_base'></a>\n",
    "## 2.1.3 Exercise: Build and Run the Base Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the test2 app\n",
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test2-rtsp_out-1SGIE/\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the DeepStream app\n",
    "Open the VLC media player on your laptop:\n",
    "- Click \"Media\" and open the  \"Open Network Stream\" dialog\n",
    "- Set the URL to `rtsp://192.168.55.1:8554/ds-test`\n",
    "- Start execution of the cell below\n",
    "- Click \"Play\" on your VLC media player right after you start executing the cell.  \n",
    "\n",
    "The stream will start shortly from the Jetson Nano and display in the media player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the app\n",
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test2-rtsp_out-1SGIE/\n",
    "!./deepstream-test2-app /home/dlinano/deepstream_sdk_v4.0.2_jetson/samples/streams/sample_720p.h264"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_sgie2'></a>\n",
    "# 2.2 Add a Plugin to a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following small sections, the code and configuration required for the SGIE1 plugin addition are highlighted.  Adding additional SGIE-n networks require the same steps: **define, instantiate, bin/link, and configure**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_define'></a>\n",
    "## 2.2.1 Define\n",
    "Define a configuration file reference in the code for the new plugin.  A constant is created in the example code for referencing the SGIE1 config file:\n",
    "```c\n",
    "#define SGIE1_CONFIG_FILE \"dstest2_sgie1_config.txt\"\n",
    "```\n",
    "\n",
    "Define a unique ID number for SGIE1. This number must match the `gie-unique-id` property provided in the configuration file.\n",
    "\n",
    "```c\n",
    "/* gie_unique_id is one of the properties in the above dstest2_sgiex_config.txt\n",
    " * files. These should be unique and known when we want to parse the Metadata\n",
    " * respective to the sgie labels. Ideally these should be read from the config\n",
    " * files but for brevity we ensure they are the same. */\n",
    "\n",
    "guint sgie1_unique_id = 2;\n",
    "```\n",
    "\n",
    "Initialize a GstElement object pointer for `sgie1`\n",
    "```c\n",
    "  GstElement *pipeline = NULL, *source = NULL, *h264parser = NULL,\n",
    "      *decoder = NULL, *streammux = NULL, *sink = NULL, *pgie = NULL, *nvvidconv = NULL,\n",
    "      *nvosd = NULL, *sgie1 = NULL, *nvtracker = NULL,\n",
    "      *encoder = NULL, *rtppay = NULL, *transform = NULL, *cap_filter = NULL;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_instantiate'></a>\n",
    "## 2.2.2 Instantiate\n",
    "The plugin is instantiated with a unique name (`sgie1`) and included in error handling with the other instantiated plugins *(Note: the sample snippets below are abbreviated code for clarity purposes)*:\n",
    "```c\n",
    "...\n",
    "    \n",
    "  /* Use nvinfer to run inferencing on decoder's output,\n",
    "   * behaviour of inferencing is set through config file */\n",
    "  pgie = gst_element_factory_make (\"nvinfer\", \"primary-nvinference-engine\");\n",
    "\n",
    "  /* We need to have a tracker to track the identified objects */\n",
    "  nvtracker = gst_element_factory_make (\"nvtracker\", \"tracker\");\n",
    "\n",
    "  /* We need three secondary gies so let's create 3 more instances of\n",
    "     nvinfer */\n",
    "  sgie1 = gst_element_factory_make (\"nvinfer\", \"secondary1-nvinference-engine\");\n",
    "\n",
    "\n",
    "...\n",
    "    \n",
    "  if (!source || !h264parser || !decoder || !pgie ||\n",
    "      !nvtracker || !sgie1 || \n",
    "      !nvvidconv || !nvosd || !sink) {\n",
    "    g_printerr (\"One element could not be created. Exiting.\\n\");\n",
    "    return -1;\n",
    "  } \n",
    "\n",
    "...\n",
    "    \n",
    "```\n",
    "\n",
    "The configuration filename (already assigned to the `SGIE1_CONFIG_FILE` constant) is assigned as a property:\n",
    "```c\n",
    "...\n",
    "    \n",
    "  /* Set all the necessary properties of the nvinfer element,\n",
    "   * the necessary ones are : */\n",
    "  g_object_set (G_OBJECT (pgie), \"config-file-path\", PGIE_CONFIG_FILE, NULL);\n",
    "  g_object_set (G_OBJECT (sgie1), \"config-file-path\", SGIE1_CONFIG_FILE, NULL);\n",
    "\n",
    "...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_binandlink'></a>\n",
    "## 2.2.3 Bin and Link\n",
    "Finally, the pipeline elements are put in a bin and linked together, with some additional error handling:\n",
    "```c\n",
    "...\n",
    "    \n",
    "  /* Set up the pipeline */\n",
    "  /* we add all elements into the pipeline */\n",
    "  /* decoder | pgie1 | nvtracker | sgie1 | sgie2 | sgie3 | etc.. */\n",
    "  gst_bin_add_many (GST_BIN (pipeline),\n",
    "      source, h264parser, decoder, streammux, pgie, nvtracker, sgie1,\n",
    "      nvvidconv, nvosd, transform, cap_filter, encoder, rtppay, sink, NULL);\n",
    "\n",
    "...\n",
    "    \n",
    "  if (!gst_element_link_many (streammux, pgie, nvtracker, sgie1,\n",
    "      nvvidconv, nvosd, transform, cap_filter, encoder, rtppay, sink, NULL)) {\n",
    "    g_printerr (\"Elements could not be linked. Exiting.\\n\");\n",
    "    return -1;\n",
    "  }\n",
    "\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_configure'></a>\n",
    "## 2.2.4 Configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to defining, instantiating, binning, and linking SGIE1 in the C code, configuration files are required for each `Gst-nvinfer` instance, plus one for the `Gst-nvtracker` instance.\n",
    "\n",
    "* [dstest2_pgie_config.txt](../deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test2-rtsp_out-1SGIE/dstest2_pgie_config.txt) configures the same 4-class object detection model you've already worked with, detecting vehicles, bicycles, persons, and road signs.\n",
    "* [dstest2_sgie1_config.txt](../deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test2-rtsp_out-1SGIE/dstest2_sgie1_config.txt) configures the secondary classification network to determine the color of a vehicle image.  The configuration file specifies, among other things, that __only vehicle objects will be analyzed__. The required parameters for this file are a little different because it is a _classifier_ network, whereas the primary network is a _detector_ network.\n",
    "* [dstest2_tracker_config.txt](../deepstream_sdk_v4.0.2_jetson/sources/apps/dli_apps/deepstream-test2-rtsp_out-1SGIE/dstest2_tracker_config.txt) configures the tracking libraries necessary to carry forward the detected images from one frame to the next. The `tracker_config.yml` file is required to further define the low-level library used.\n",
    "\n",
    "Property definitions for the configuration files can be found in the DeepStream Plugin Manual at [docs.nvidia.com/metropolis/deepstream/plugin-manual](docs.nvidia.com/metropolis/deepstream/plugin-manual). (Note: you will need to copy/paste the address if your Nano is not connected to the internet directly.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_ex_change'></a>\n",
    "## 2.2.5 Exercise: Add SGIE2 Plugin to the Pipeline\n",
    "Create a new app based on `deepstream-test2-rtsp_out-1SGIE` that classifies not only colors, using SGIE1, but also car make, using an additional network, SGIE2.\n",
    "\n",
    "You'll need the following specific information about the network model for your configuration file:<br>\n",
    "**Files for the model engine:**\n",
    "```c\n",
    "model-engine-file=../../../../samples/models/Secondary_CarMake/resnet18.caffemodel_b16_fp16.engine\n",
    "model-file=../../../../samples/models/Secondary_CarMake/resnet18.caffemodel\n",
    "proto-file=../../../../samples/models/Secondary_CarMake/resnet18.prototxt\n",
    "mean-file=../../../../samples/models/Secondary_CarMake/mean.ppm\n",
    "labelfile-path=../../../../samples/models/Secondary_CarMake/labels.txt\n",
    "int8-calib-file=../../../../samples/models/Secondary_CarMake/cal_trt.bin\n",
    "```\n",
    "**Unique ID**\n",
    "```c\n",
    "gie-unique-id=3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new app located at /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/my_apps/dst2-two-sgie \n",
    "#      based on deepstream-test2-rtsp_out-1SGIE\n",
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps\n",
    "!mkdir -p my_apps/dst2-two-sgie\n",
    "!cp -rfv dli_apps/deepstream-test2-rtsp_out-1SGIE/* my_apps/dst2-two-sgie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new configuration file for SGIE2 \n",
    "#      based on the one already existing for SGIE1.\n",
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/my_apps/dst2-two-sgie\n",
    "!cp dstest2_sgie1_config.txt dstest2_sgie2_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what you just learned in the, modify [deepstream_test2_app.c](../deepstream_sdk_v4.0.2_jetson/sources/apps/my_apps/dst2-two-sgie/deepstream_test2_app.c) and [dstest2_sgie2_config.txt](../deepstream_sdk_v4.0.2_jetson/sources/apps/my_apps/dst2-two-sgie/dstest2_sgie2_config.txt) to add SGIE2 to the pipeline. Then build and run the app to see if it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the app\n",
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/my_apps/dst2-two-sgie\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the app\n",
    "%cd /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/my_apps/dst2-two-sgie\n",
    "!./deepstream-test2-app /home/dlinano/deepstream_sdk_v4.0.2_jetson/samples/streams/sample_720p.h264"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How did you do?\n",
    "If you see something like this image, you did it!  If not, keep trying, or take a peek at the solution code in the solutions directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/02_color_and_make.png\" alt=\"color and make\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_final'></a>\n",
    "# 2.3 Put It All Together\n",
    "Great job adding SGIE2!  You've learned how to define, instantiate, link, and configure a multiple network DeepStream application.  Let's take it one step further by adding another network in a new app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='02_ex_challenge'></a>\n",
    "## 2.3.1 Exercise: Three Secondary Networks\n",
    "Create a new app based on `deepstream-test2-rtsp_out-1SGIE` that classifies colors, makes, and vehicle types. Fill in the following cells with appropriate commands to create, build, and run your app. To edit your files, use the JupyterLab file browser at left to navigate to the correct folder; then, double click on the file you wish to open and edit.\n",
    "\n",
    "The configuration information for vehicle make was provided in the previous exercise.  For the vehicle type configuration, you'll need the following:<br>\n",
    "**Files for the model engine:**\n",
    "```c\n",
    "model-engine-file=../../../../samples/models/Secondary_VehicleTypes/resnet18.caffemodel_b16_fp16.engine\n",
    "model-file=../../../../samples/models/Secondary_VehicleTypes/resnet18.caffemodel\n",
    "proto-file=../../../../samples/models/Secondary_VehicleTypes/resnet18.prototxt\n",
    "mean-file=../../../../samples/models/Secondary_VehicleTypes/mean.ppm\n",
    "labelfile-path=../../../../samples/models/Secondary_VehicleTypes/labels.txt\n",
    "int8-calib-file=../../../../samples/models/Secondary_VehicleTypes/cal_trt.bin\n",
    "```\n",
    "**Unique ID**\n",
    "```c\n",
    "gie-unique-id=4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Create a new app located at /home/dlinano/deepstream_sdk_v4.0.2_jetson/sources/apps/my_apps/dst2-three-sgie \n",
    "#      based on deepstream-test2-rtsp_out-1SGIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Create a new configuration files for SGIOE2 and SGIE3\n",
    "#      based on the one already existing for SGIE1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify [deepstream_test2_app.c](../deepstream_sdk_v4.0.2_jetson/sources/apps/my_apps/dst2-two-sgie/deepstream_test2_app.c) and the configuration files as needed. Then build and run the app to see if it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Build the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Run the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How did you do?\n",
    "If you see something like this image, you've mastered multiple networks!  If not, keep trying, or take a peek at the solution code in the solutions directory.  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/02_3sgie.png\" alt=\"4 networks\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "You've learned how to add classifier networks to a DeepStream pipeline to create multiple network DeepStream apps.  <br>\n",
    "Move on to [3.0 MultiStream Application](./03_MultiStream.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/DLI Header.png\" alt=\"Header\" width=\"400\"></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
